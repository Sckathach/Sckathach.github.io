@article{mordvintsev_inceptionism_2015,
  author = {Alexander Mordvintsev, Christopher Olah, Mike Tyka},
  year = {2015},
  title = {Inceptionism: Going Deeper into Neural Networks},
  journal = {Google Research Blog}
}

@article{hasting_introduction_2024,
  author = {Sarah Hastings-Woodhouse},
  title = {Introduction to Mechanistic Interpretability},
  year = {2024},
  url = {https://aisafetyfundamentals.com/blog/introduction-to-mechanistic-interpretability/}
}

@article{lambert_illustrating_2022,
  author = {Lambert, Nathan and Castricato, Louis and von Werra, Leandro and Havrilla, Alex},
  title = {Illustrating Reinforcement Learning from Human Feedback (RLHF)},
  journal = {Hugging Face Blog},
  year = {2022},
  note = {https://huggingface.co/blog/rlhf},
}

@article{bai_constitutional_2022,
	title = {Constitutional {AI}: Harmlessness from {AI} Feedback},
	shorttitle = {Constitutional {AI}},
	abstract = {As {AI} systems become more capable, we would like to enlist their help to supervise other {AIs}. We experiment with methods for training a harmless {AI} assistant through selfimprovement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as ‘Constitutional {AI}’. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then ﬁnetune the original model on revised responses. In the {RL} phase, we sample from the ﬁnetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of {AI} preferences. We then train with {RL} using the preference model as the reward signal, i.e. we use ‘{RL} from {AI} Feedback’ ({RLAIF}). As a result we are able to train a harmless but nonevasive {AI} assistant that engages with harmful queries by explaining its objections to them. Both the {SL} and {RL} methods can leverage chain-of-thought style reasoning to improve the human-judged performance and transparency of {AI} decision making. These methods make it possible to control {AI} behavior more precisely and with far fewer human labels.},
	number = {{arXiv}:2212.08073},
	publisher = {{arXiv}},
	author = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and {McKinnon}, Cameron and Chen, Carol and Olsson, Catherine and Olah, Christopher and Hernandez, Danny and Drain, Dawn and Ganguli, Deep and Li, Dustin and Tran-Johnson, Eli and Perez, Ethan and Kerr, Jamie and Mueller, Jared and Ladish, Jeffrey and Landau, Joshua and Ndousse, Kamal and Lukosuite, Kamile and Lovitt, Liane and Sellitto, Michael and Elhage, Nelson and Schiefer, Nicholas and Mercado, Noemi and {DasSarma}, Nova and Lasenby, Robert and Larson, Robin and Ringer, Sam and Johnston, Scott and Kravec, Shauna and Showk, Sheer El and Fort, Stanislav and Lanham, Tamera and Telleen-Lawton, Timothy and Conerly, Tom and Henighan, Tom and Hume, Tristan and Bowman, Samuel R. and Hatfield-Dodds, Zac and Mann, Ben and Amodei, Dario and Joseph, Nicholas and {McCandlish}, Sam and Brown, Tom and Kaplan, Jared},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2212.08073 [cs]},
	keywords = {llm, rlhf, safety},
}


@article{casper_openproblems_2023,
      title={Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback}, 
      author={Stephen Casper and Xander Davies and Claudia Shi and Thomas Krendl Gilbert and Jérémy Scheurer and Javier Rando and Rachel Freedman and Tomasz Korbak and David Lindner and Pedro Freire and Tony Wang and Samuel Marks and Charbel-Raphaël Segerie and Micah Carroll and Andi Peng and Phillip Christoffersen and Mehul Damani and Stewart Slocum and Usman Anwar and Anand Siththaranjan and Max Nadeau and Eric J. Michaud and Jacob Pfau and Dmitrii Krasheninnikov and Xin Chen and Lauro Langosco and Peter Hase and Erdem Bıyık and Anca Dragan and David Krueger and Dorsa Sadigh and Dylan Hadfield-Menell},
      year={2023},
      eprint={2307.15217},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2307.15217}, 
}

@article{elhage_superposition_2022,
   title={Toy Models of Superposition},
   author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and Grosse, Roger and McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Wattenberg, Martin and Olah, Christopher},
   year={2022},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2022/toy_model/index.html}
}

@article{olah_zoom_2020,
  author = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  title = {Zoom In: An Introduction to Circuits},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/circuits/zoom-in},
  doi = {10.23915/distill.00024.001}
}

@article{olah_overview_2020,
  author = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  title = {An Overview of Early Vision in InceptionV1},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/circuits/early-vision},
  doi = {10.23915/distill.00024.002}
}

@article{jiang_discrete_2019,
	author = {Jiang, Rundong and Li, Ming and Tang, Shiming},
	title = {Discrete neural clusters encode orientation, curvature and corners in macaque V4},
	year = {2019},
	doi = {10.1101/808907},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {As an intermediate stage of the ventral visual pathway, V4 plays a crucial role in transforming basic orientation information into higher-ordered object representations. However, the neural mechanisms underlying the encoding of simple, complex and intermediate features in V4 remain poorly understood. Using two-photon calcium imaging in awake macaques, we recorded the responses of large populations of V4 neurons to thousands of natural images. To understand these high-dimensional data sets, we performed dimensional reduction analysis on the neuronal population responses. We found orthogonal dimensions encoding orientation and more complex features, with curves and corners represented separately. These distinct feature dimensions were encoded by spatially clustered subpopulations of neurons organized in iso-orientation and curvature domains. Using synthetic stimuli, we confirmed that curvature and corner selective neurons in V4 were tuned to integral features rather than combinations of local orientation compartments. Our results show that curves and corners are encoded by neurons clustered into functional domains separate from orientation. This functionally specific population architecture may serve to facilitate local computations that expedite more complex shape and object representations at higher levels of the ventral pathway.},
	journal = {bioRxiv}
}

@article{nanda_comprehensive_2022, 
  title={A Comprehensive Mechanistic Interpretability Explainer & Glossary}, 
  url={https://neelnanda.io/glossary}, 
  author={Nanda, Neel}, 
  year={2022}, 
  month={Dec}
}

@article{mikolov_efficient_2013,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1301.3781}, 
}

@article{socher_zeroshot_2013,
      title={Zero-Shot Learning Through Cross-Modal Transfer}, 
      author={Richard Socher and Milind Ganjoo and Hamsa Sridhar and Osbert Bastani and Christopher D. Manning and Andrew Y. Ng},
      year={2013},
      eprint={1301.3666},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1301.3666}, 
}

@article{turner_activation_2024,
      title={Activation Addition: Steering Language Models Without Optimization}, 
      author={Alexander Matt Turner and Lisa Thiergart and Gavin Leech and David Udell and Juan J. Vazquez and Ulisse Mini and Monte MacDiarmid},
      year={2024},
      eprint={2308.10248},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.10248}, 
}

@article{ilharco_editing_2023,
      title={Editing Models with Task Arithmetic}, 
      author={Gabriel Ilharco and Marco Tulio Ribeiro and Mitchell Wortsman and Suchin Gururangan and Ludwig Schmidt and Hannaneh Hajishirzi and Ali Farhadi},
      year={2023},
      eprint={2212.04089},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2212.04089}, 
}

@article{wortsman_modelsoups_2022,
      title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time}, 
      author={Mitchell Wortsman and Gabriel Ilharco and Samir Yitzhak Gadre and Rebecca Roelofs and Raphael Gontijo-Lopes and Ari S. Morcos and Hongseok Namkoong and Ali Farhadi and Yair Carmon and Simon Kornblith and Ludwig Schmidt},
      year={2022},
      eprint={2203.05482},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2203.05482}, 
}

@article{lucas_analyzing_2021,
      title={Analyzing Monotonic Linear Interpolation in Neural Network Loss Landscapes}, 
      author={James Lucas and Juhan Bae and Michael R. Zhang and Stanislav Fort and Richard Zemel and Roger Grosse},
      year={2021},
      eprint={2104.11044},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2104.11044}, 
}

@article{izmailov_averaging_2019,
      title={Averaging Weights Leads to Wider Optima and Better Generalization}, 
      author={Pavel Izmailov and Dmitrii Podoprikhin and Timur Garipov and Dmitry Vetrov and Andrew Gordon Wilson},
      year={2019},
      eprint={1803.05407},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1803.05407}, 
}

@article{ilharco_patching_2022,
      title={Patching open-vocabulary models by interpolating weights}, 
      author={Gabriel Ilharco and Mitchell Wortsman and Samir Yitzhak Gadre and Shuran Song and Hannaneh Hajishirzi and Simon Kornblith and Ali Farhadi and Ludwig Schmidt},
      year={2022},
      eprint={2208.05592},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2208.05592}, 
}

@article{zou_representation_2023,
      title={Representation Engineering: A Top-Down Approach to AI Transparency}, 
      author={Andy Zou and Long Phan and Sarah Chen and James Campbell and Phillip Guo and Richard Ren and Alexander Pan and Xuwang Yin and Mantas Mazeika and Ann-Kathrin Dombrowski and Shashwat Goel and Nathaniel Li and Michael J. Byun and Zifan Wang and Alex Mallen and Steven Basart and Sanmi Koyejo and Dawn Song and Matt Fredrikson and J. Zico Kolter and Dan Hendrycks},
      year={2023},
      eprint={2310.01405},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.01405}, 
}

@article{olsson_incontext_2022,
      title={In-context Learning and Induction Heads}, 
      author={Catherine Olsson and Nelson Elhage and Neel Nanda and Nicholas Joseph and Nova DasSarma and Tom Henighan and Ben Mann and Amanda Askell and Yuntao Bai and Anna Chen and Tom Conerly and Dawn Drain and Deep Ganguli and Zac Hatfield-Dodds and Danny Hernandez and Scott Johnston and Andy Jones and Jackson Kernion and Liane Lovitt and Kamal Ndousse and Dario Amodei and Tom Brown and Jack Clark and Jared Kaplan and Sam McCandlish and Chris Olah},
      year={2022},
      eprint={2209.11895},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2209.11895}, 
}

@article{power_grokking_2022,
      title={Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets}, 
      author={Alethea Power and Yuri Burda and Harri Edwards and Igor Babuschkin and Vedant Misra},
      year={2022},
      eprint={2201.02177},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2201.02177}, 
}

@article{pan_effect_2022,
      title={The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models}, 
      author={Alexander Pan and Kush Bhatia and Jacob Steinhardt},
      year={2022},
      eprint={2201.03544},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2201.03544}, 
}

@article{bricken_monosemanticity_2023,
     title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
     author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
     year={2023},
     journal={Transformer Circuits Thread},
     note={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
}

@article{arditi_refusal_2024,
      title={Refusal in Language Models Is Mediated by a Single Direction}, 
      author={Andy Arditi and Oscar Obeso and Aaquib Syed and Daniel Paleka and Nina Panickssery and Wes Gurnee and Neel Nanda},
      year={2024},
      eprint={2406.11717},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.11717}, 
}

@article{nanda_transformerlens_2022,
    title = {TransformerLens},
    author = {Neel Nanda and Joseph Bloom},
    year = {2022},
    howpublished = {\url{https://github.com/TransformerLensOrg/TransformerLens}},
}

@article{bloom_sae_2024,
   title = {SAELens},
   author = {Joseph Bloom and David Chanin},
   year = {2024},
   howpublished = {\url{https://github.com/jbloomAus/SAELens}},
}

@article{conmy_automated_2023,
      title={Towards Automated Circuit Discovery for Mechanistic Interpretability}, 
      author={Arthur Conmy and Augustine N. Mavor-Parker and Aengus Lynch and Stefan Heimersheim and Adrià Garriga-Alonso},
      year={2023},
      eprint={2304.14997},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2304.14997}, 
}
@article{bereska_mechanistic_2024,
      title={Mechanistic Interpretability for AI Safety -- A Review}, 
      author={Leonard Bereska and Efstratios Gavves},
      year={2024},
      eprint={2404.14082},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2404.14082}, 
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@article{zou_universal_2023,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{hayase_query_2024,
      title={Query-Based Adversarial Prompt Generation}, 
      author={Jonathan Hayase and Ema Borevkovic and Nicholas Carlini and Florian Tramèr and Milad Nasr},
      year={2024},
      eprint={2402.12329},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.12329}, 
}

@article{ebrahimi_hotflip_2017,
      title = {HotFlip: White-Box Adversarial Examples for Text Classification},
      author={Javid Ebrahimi, Anyi Rao, Daniel Lowd, Dejing Dou},
      year={2017},
      eprint={1712.06751},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1712.06751},
}


@misc{haize_sota_2024,
      title={Making a SOTA Adversarial Attack on LLMs 38x Faster},
      author={Haize},
      year={2024},
      url={https://blog.haizelabs.com/posts/acg/}
}