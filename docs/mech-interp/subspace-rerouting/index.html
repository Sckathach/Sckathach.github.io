<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.6">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Le magicien quantique">
<meta name="dcterms.date" content="2025-03-18">

<title>Subspace Rerouting: Using Mechanistic Interpretability to Craft Adversarial Attacks against Large Language Models – Sckathach’s posts</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../assets/favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-68d38218fc9705968688502b5ae76c5a.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-a711777f2d1d1ff15f4d534e28ea60e9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": true,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Subspace Rerouting: Using Mechanistic Interpretability to Craft Adversarial Attacks against Large Language Models – Sckathach’s posts">
<meta property="og:description" content="The very super website of the super Sckathach!">
<meta property="og:image" content="https://sckathach.github.io/mech-interp/subspace-rerouting/assets/wanted.png">
<meta property="og:site_name" content="Sckathach's posts">
<meta property="og:image:height" content="646">
<meta property="og:image:width" content="500">
<meta name="twitter:title" content="Subspace Rerouting: Using Mechanistic Interpretability to Craft Adversarial Attacks against Large Language Models – Sckathach’s posts">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://sckathach.github.io/mech-interp/subspace-rerouting/assets/wanted.png">
<meta name="twitter:image-height" content="646">
<meta name="twitter:image-width" content="500">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Sckathach’s posts</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../404ctf/index.html"> 
<span class="menu-text">404 CTF</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../mech-interp/exploring-adversarial-mi/index.html"> 
<span class="menu-text">Exploring</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../mech-interp/subspace-rerouting/index.html" aria-current="page"> 
<span class="menu-text">SSR</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/sckathach" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-prelim" id="toc-sec-prelim" class="nav-link active" data-scroll-target="#sec-prelim">Gradient-based jailbreaks</a></li>
  <li><a href="#sec-replication" id="toc-sec-replication" class="nav-link" data-scroll-target="#sec-replication">Understanding jailbreaks</a></li>
  <li><a href="#sec-method" id="toc-sec-method" class="nav-link" data-scroll-target="#sec-method">Introducing Subspace Rerouting (SSR)</a></li>
  <li><a href="#sec-interp" id="toc-sec-interp" class="nav-link" data-scroll-target="#sec-interp">Interpretable jailbreaks?</a></li>
  <li><a href="#sec-lens" id="toc-sec-lens" class="nav-link" data-scroll-target="#sec-lens">SAE ???</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/Sckathach/Sckathach.github.io/edit/main/mech-interp/subspace-rerouting/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/Sckathach/Sckathach.github.io/blob/main/mech-interp/subspace-rerouting/index.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/Sckathach/Sckathach.github.io/issues" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Subspace Rerouting: Using Mechanistic Interpretability to Craft Adversarial Attacks against Large Language Models</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Le magicien quantique </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">March 18, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div id="fig-wanted" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-wanted-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/wanted.png" class="img-fluid figure-img"></p>
<figcaption>wanted</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wanted-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: <em>Warning, this head is easily distracted by adversarial perturbations and should not be relied on to ensure safety</em>
</figcaption>
</figure>
</div>
<p><em>Code and notebooks available here: <a href="https://github.com/Sckathach/subspace-rerouting" class="uri">https://github.com/Sckathach/subspace-rerouting</a>.</em></p>
<p>This work follows the interpretability analysis of jailbreaks on LLM made by <span class="citation" data-cites="arditi_refusal_2024">Arditi et al. (<a href="#ref-arditi_refusal_2024" role="doc-biblioref">2024</a>)</span>, <span class="citation" data-cites="he_jailbreaklens_2024">He et al. (<a href="#ref-he_jailbreaklens_2024" role="doc-biblioref">2024</a>)</span>, and <a href="https://sckathach.github.io/mech-interp/exploring-adversarial-mi/">my previous failed attempt</a> on the subject. It adapts the Greedy Coordinate Gradient (GCG) attack to target virtually any subspace in the model, which not only enables quick jailbreaks but also allows runtime interventions like vector steering or direction ablations to be converted into adversarial perturbations in the input. Perturbations that trigger desired behaviors without further intervention.</p>
<p>And sometimes, the perturbation is interpretable!</p>
<p><img src="assets/af_conversation_violet.png" class="img-fluid"></p>
<p>Removing the word “gracefully” makes the jailbreak fail, as expected from a “slightly robust” model:</p>
<p><img src="assets/af_conversation_orange.png" class="img-fluid"></p>
<p>This run also yielded perturbations like: “gently ensuring safety”, and more general incitations to perform the task in a “safe” manner.</p>
<p>I’ve published a paper with the technical details: <a href="https://arxiv.org/abs/2503.06269" class="uri">https://arxiv.org/abs/2503.06269</a>.</p>
<p>The goal of this post is to present the mechanistic interpretability component of the work, along with some findings I didn’t include in the paper. It’s organized into several sections:</p>
<ul>
<li><strong>Preliminaries</strong> that briefly introduce “classical” gradient-based attacks against LLMs (<a href="#sec-prelim" class="quarto-xref">Section&nbsp;1</a>)</li>
<li>A presentation of <strong>interpretability techniques used to study jailbreaks</strong> (<a href="#sec-replication" class="quarto-xref">Section&nbsp;2</a>)</li>
<li>An introduction to the <strong>Subspace Rerouting (SSR) algorithm</strong> (<a href="#sec-method" class="quarto-xref">Section&nbsp;3</a>)</li>
<li>Some first <strong>interpretations of generated jailbreaks</strong> (<a href="#sec-interp" class="quarto-xref">Section&nbsp;4</a>)</li>
<li><strong>SAE ???</strong> (<a href="#sec-lens" class="quarto-xref">Section&nbsp;5</a>)</li>
</ul>
<p><strong>TLDR:</strong> If steering the model during inference modifies its behavior, it’s possible (sometimes) <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> to modify the input prompt into “prompt + something” such that the resulting activations will be close to those achieved with the intervention. This leads to a similar change in behavior without requiring intervention during inference. It’s also possible (sometimes) <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> to use <em>reverse</em>-logit lens techniques to obtain interesting results.</p>
<section id="sec-prelim" class="level2">
<h2 class="anchored" data-anchor-id="sec-prelim">Gradient-based jailbreaks</h2>
<p>Among the thousand ways to jailbreak a model - that is, making it behave contrary to its alignment - there are white-box algorithms that use the model’s weights to compute adversarial perturbations. These perturbations can make the LLM output harmful content like bomb-making instructions. One notable algorithm in this domain is the Greedy Coordinate Gradient (GCG) attack, which takes as input a harmful instruction <span class="math inline">\(x\)</span>, a target <span class="math inline">\(t\)</span>, and computes an adversarial suffix <span class="math inline">\(s\)</span>, such that <span class="math inline">\(LLM(x + s)\)</span> is likely to output <span class="math inline">\(t\)</span>.</p>
<p>For those unfamiliar with GCG, it works like this, given a harmful instruction:</p>
<p><img src="assets/af_gcg1.png" class="img-fluid"></p>
<p>It adds a dummy suffix:</p>
<p><img src="assets/af_gcg2.png" class="img-fluid"></p>
<p>Prepares a target:</p>
<p><img src="assets/af_gcg3.png" class="img-fluid"></p>
<p>And optimizes the suffix (via backpropagation and HotFlip to generate new tokens):</p>
<p><img src="assets/af_gcg4.png" class="img-fluid"></p>
<p>The goal is for the full adversarial input to bypass security filters.</p>
<p>While effective on some older models, the GCG attack can require hours of computation and often fails on newer models:</p>
<div id="fig-gcgfail" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gcgfail-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/af_gcg5.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gcgfail-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: This attack was performed on Gemma 2 2b using the nanoGCG algorithm from Gray Swan. It took ~1h30 and failed. The algorithm achieved its objective - the model begins with the target - but as it quickly reverts toward a harmless response, it ultimately refuses to answer.
</figcaption>
</figure>
</div>
<p>This led to an obvious question: Why optimize end-to-end while treating the model as a “black box”? Is it possible to use mechanistic interpretability insights to enhance the attack?</p>
<details>
<summary>
Spoiler
</summary>
<p><em>Yes</em></p>
</details>
</section>
<section id="sec-replication" class="level2">
<h2 class="anchored" data-anchor-id="sec-replication">Understanding jailbreaks</h2>
<p>For those who haven’t read the excellent papers: <em>Refusal is Mediated in a single direction</em> (<span class="citation" data-cites="arditi_refusal_2024">Arditi et al. (<a href="#ref-arditi_refusal_2024" role="doc-biblioref">2024</a>)</span>), <em>Jailbreak Lens</em> (<span class="citation" data-cites="he_jailbreaklens_2024">He et al. (<a href="#ref-he_jailbreaklens_2024" role="doc-biblioref">2024</a>)</span>), or <em>On the role of safety heads</em> (<span class="citation" data-cites="zhou_role_2024">Zhou et al. (<a href="#ref-zhou_role_2024" role="doc-biblioref">2024</a>)</span>), safety mechanisms can be located inside the model, even in very early layers! For instance, scanning a dataset of harmful sentences - “How to create a bomb?”, and their harmless counterparts - “How to create a website?”, reveals interesting patterns as early as ~1/3 of the way through the model:</p>
<div id="fig-pca" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pca-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="assets/pca_layer5_llama321.png" class="img-fluid figure-img"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="assets/pca_layer10_llama321.png" class="img-fluid figure-img"></p>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pca-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: PCA on the activations of the two datasets using last token representation. The model used is Llama 3.2 1b.
</figcaption>
</figure>
</div>
<p>As visible in <a href="#fig-pca" class="quarto-xref">Figure&nbsp;3</a>, it’s possible to distinguish between harmful and harmless sentences using only one direction. This direction was termed the “refusal direction” by <span class="citation" data-cites="arditi_refusal_2024">Arditi et al. (<a href="#ref-arditi_refusal_2024" role="doc-biblioref">2024</a>)</span> and can be defined as the normalized difference in means between the activations of the two datasets.</p>
<!-- ::: {.column-margin}

$$
  \hat{r}^l = \frac{\mu^l_+ - \mu^l_-}{\|\mu^l_+ - \mu^l_-\|}  \in \mathbb{R}^d
$$

::: -->
<p>This direction is impressive, as a simple cosine similarity between the activations and this direction provides insight into the model’s behavior—whether it will refuse to answer or not. Using the Logit lens (<span class="citation" data-cites="logit_lens_2020">nostalgebraist (<a href="#ref-logit_lens_2020" role="doc-biblioref">2020</a>)</span>), we can even attempt to interpret it:</p>
<div id="fig-logitlenscolor" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-logitlenscolor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/logitlens_color.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-logitlenscolor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Logit lens applied on the refusal direction found using Llama 3.2 1b. “Tôi” means “I” in Vietnamese, and “không” means “neither”.
</figcaption>
</figure>
</div>
<p><span class="citation" data-cites="he_jailbreaklens_2024">He et al. (<a href="#ref-he_jailbreaklens_2024" role="doc-biblioref">2024</a>)</span> went a step further, and instead of using a single dimension, employed probes to capture arbitrarily large subspaces. These probes—linear layers with a sigmoid activation—classify activations with over 95% accuracy as early as the third layer in most models!</p>
<p>Moreover, <span class="citation" data-cites="zhou_role_2024">Zhou et al. (<a href="#ref-zhou_role_2024" role="doc-biblioref">2024</a>)</span> found that safety mechanisms are not only localized semantically but can also be found in individual components, like attention heads. For instance, in Qwen 2.5 1.5b, a single head (I won’t specify which one :eyes:) can completely undermine the <em>slight</em> alignment of the model. More on that later.</p>
<p>With all these advances, couldn’t we improve adversarial attacks?</p>
<details>
<summary>
Hint
</summary>
<p><em>In classical adversarial attacks on image classifiers—you know, the panda transformed into a gibbon (<span class="citation" data-cites="liu_privacy_2020">Liu et al. (<a href="#ref-liu_privacy_2020" role="doc-biblioref">2020</a>)</span>)—the target is the classifier, and the goal is to transition from one class to another. Isn’t that <strong>exactly</strong> our setup?</em></p>
<p><em>input → first layers → classifier → “harmful”, that we would like to flip to “harmless”?</em></p>
</details>
<details>
<summary>
Spoiler
</summary>
<p><em>Yes</em></p>
</details>
</section>
<section id="sec-method" class="level2">
<h2 class="anchored" data-anchor-id="sec-method">Introducing Subspace Rerouting (SSR)</h2>
<p>As its name suggests, subspace rerouting is about redirecting activations from one subspace to another. For instance, from the harmful subspace identified with our linear probes into the harmless subspace. The excellent Transformer Lens library makes the implementation <em>nearly</em> trivial.</p>
<ol type="1">
<li>Take an input with dummy perturbations: “Super [MASK] input! [MASK][MASK][MASK][MASK]”.</li>
<li>Perform a forward pass until the desired layer.</li>
<li>Cache the needed activations with hooks.</li>
<li>Perform backpropagation to update the perturbation, defining the loss as the distance between the current activations and the subspace you wish to target.</li>
<li>Use the HotFlip method to find better tokens for your perturbation.</li>
<li>Loop until satisfied. <!-- 
::: {.column-margin}

$$
  \mathcal{L}(s) = \sum_k \alpha_k d_k(e_k, E_k)
$$

::: --></li>
</ol>
<p>This is a very general algorithm, not restricted to jailbreaks, as it can be applied (with the current implementation) using any hook available in Transformer Lens, targeting any number of different subspaces across different layers, placing perturbations anywhere in the input, and working with any kind of subspace.</p>
<p>The most straightforward subspaces to target are those defined by linear probes. The loss is simply the probe’s loss function, and SSR will handle the rest, finding a perturbation to reroute your activations:</p>
<!-- ::: {.column-margin}

$$
  \mathcal{L}(s) = - \log(1 - p(\mathcal{R}^{l}(x+s)))
$$

::: -->
<div id="fig-probes" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-probes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/rerouting_llama_probe.png" class="img-fluid figure-img"></p>
<figcaption>Rerouting visualization</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-probes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Rerouting activations using probes, again, on Llama 3.2 1b.
</figcaption>
</figure>
</div>
<p>As the targeted layer is the 5th, and the targeted subspace has a dimension of ~2, the optimization takes literally 16 seconds.</p>
<p>The question we can now ask is: Is this perturbation sufficient to jailbreak the model?</p>
<details>
<summary>
Spoiler
</summary>
<p><em>Yes</em></p>
<p><em>You can examine the hundreds of jailbreaks I published on Hugging Face: <a href="https://huggingface.co/datasets?other=arxiv:2503.06269" class="uri">https://huggingface.co/datasets?other=arxiv:2503.06269</a></em>.</p>
</details>
<p>Moreover, it works with probes, but as mentioned, you can define subspaces however you want. For instance, using the refusal direction defined earlier, we can define the refusal subspace as the set of activations with a high cosine similarity to the refusal direction. Conversely, the acceptance subspace can be defined as the set of vectors having a high <em>negative</em> cosine similarity with the refusal direction.</p>
<!-- ::: {.column-margin}

The loss function combines steering and orthogonal stability objectives:

$$
  \mathcal{L}(s) = \mathcal{L}_{\text{steering}}(s) + \mathcal{L}_{\text{orthogonal stability}}(s)
$$

$$
  \mathcal{L}_{\text{steering}}(s) = |(1 - a)\langle\hat{r}, e_*\rangle - \langle e, \hat{r}\rangle|^2 
$$

$$
  \mathcal{L}_{\text{orthogonal stability}}(s) = \Vert \langle\hat{r}, e_*\rangle^T - \langle\hat{r}, e\rangle^T \Vert ^2
$$

::: -->
<p>This represents the second use of SSR that I propose, and here are the results:</p>
<div id="fig-steering" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-steering-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/cosim_short.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-steering-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Mean cosine similarities between four activation sets and the refusal directions computed at each layer on Llama 3.2 1b. The four runs are: a forward pass on vanilla harmful sentences (<strong>Normal</strong>), a forward pass with random suffixes of length 5 (<strong>Random</strong>), a forward pass with steering intervention at layers 5, 8, 10, 14 using <span class="math inline">\(a = −2\)</span> (<strong>Intervention</strong>), and a forward pass with successful suffixes - of length 5 - generated by SSR, with layers 5, 8, 10, 14 as targets, and <span class="math inline">\(a = −3\)</span> (<strong>SSR</strong>).
</figcaption>
</figure>
</div>
<p>Disregarding my <em>slight</em> cheating (choosing a higher coefficient for my algorithm than for the intervention baseline), the results are much more impressive than I expected. SSR found suffixes that reproduced the same activation patterns as the runtime steering, but without requiring any intervention during the forward pass.</p>
<p>Beyond being sufficient to jailbreak the model, these results also reveal an interesting phenomenon: activations steered at runtime to be considered harmless quickly revert to their “harmful state”. Meanwhile, SSR generated inputs that consistently maintain a negative cosine similarity with the refusal direction, following a more “natural” path.</p>
<p>My hypothesis is that steering at runtime produces activations that are impossible to achieve under normal conditions—i.e., no input can naturally produce these activations, so these perturbations are brought back toward normality by the following layers. Computing the KL divergence between the normal run and the three other runs partially supports this hypothesis:</p>
<div id="fig-steering" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-steering-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/kl_divs.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-steering-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: KL divergence between the normal run and the three other runs.
</figcaption>
</figure>
</div>
<p>Unfortunately, I’ll stop this analysis here to avoid overreaching in my interpretations.</p>
<p>Lastly, I must discuss attention heads. As found by <span class="citation" data-cites="arditi_refusal_2024">Arditi et al. (<a href="#ref-arditi_refusal_2024" role="doc-biblioref">2024</a>)</span>, successful jailbreak suffixes tend to “hijack” the attention of safety heads, such that these heads focus only on the gibberish suffix rather than the actual harmful content in the instruction. The example presented in <a href="#fig-wanted" class="quarto-xref">Figure&nbsp;1</a> is as follows: the suffix “:: Short YAML” is successful—the model (Qwen 2.5 1.5b) agrees to answer—while the suffix “:: Long YAML” is unsuccessful, with the model responding “I can’t”.</p>
<div id="fig-hijack" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hijack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/hijacking_attention_shorter.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hijack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Visualization of the attention patterns of L25H4 at the last token’s position. In the unsuccessful attempt (top), the attention of the last token focuses on the harmful word “exploit”, while in the successful attempt (bottom), attention is redirected to the seemingly harmless token “YAML” in the suffix.
</figcaption>
</figure>
</div>
<p>Like refusal directions and probes, this phenomenon can be exploited to generate attacks by “rerouting the attention” from harmful tokens to harmless ones. In practice, I reproduced the effects of jailbreaks artificially by defining my loss as the negative sum of the rectangular slice of the attention pattern corresponding to my perturbation (taken after the softmax). Hence, if the sum is large, it means the head is paying significant attention to my perturbations.</p>
<!-- ::: {.column-margin}

$$
  \mathcal{L}(s) = -\sum_k \alpha_k \mathcal{H}_{l_k,h_k}(x+s)
$$

::: -->
<p>This approach didn’t produce particularly impressive jailbreaks, but it still performed slightly better than the non-mechanistic baseline. What I found most striking is that the success rate is <span class="math inline">\(\gt 0\)</span> on every model, even though my optimization only targets one particular attention pattern of one particular head…</p>
<p>Before you ask, I tried targeting randomly selected heads to verify whether success is due merely to input perturbation or if the objective makes sense. For Qwen 2.5 1.5b, nearly any head chosen in the last layers can be targeted to produce jailbreaks. The model is poorly aligned; almost any perturbation seems to break it. However, this isn’t the case for other models. This method only works on Llama 3.2 3B and Gemma 2 2b if the targeted heads are safety heads, identified either through direct logit attribution or activation patching.</p>
<p>Although I haven’t conducted extensive experiments, and there’s still much work to be done on the optimization formulation, I’m fairly confident about the approach. In any case, it demonstrates that targeting specific components is possible, or at least conceivable.</p>
</section>
<section id="sec-interp" class="level2">
<h2 class="anchored" data-anchor-id="sec-interp">Interpretable jailbreaks?</h2>
<p>Success rates and attack durations are interesting, but what’s even more fascinating is that some jailbreaks are semantically coherent and interpretable! Despite being optimized through gradient methods with a substantial dose of randomness—when continuous gradients are converted into token flips, candidate tokens are chosen using a random distribution over possible tokens—not only are some tokens coherent in a safety sense, like “safely” or “respectfully,” but some perturbations even form small meaningful phrases, like “<strong>ask natural Dumbledore</strong>” or “<strong>portrayed As Goku</strong>”, and are answered accordingly!</p>
<p><img src="assets/af_ssr2.png" class="img-fluid"></p>
<p><img src="assets/af_ssr1.png" class="img-fluid"></p>
<p>I’ll let you test these yourself. My only recommendation is to stick with short perturbations (until I find a way to properly incorporate perplexity into my loss function). For instance, 6 tokens are already difficult to interpret: “<strong>…), theme Krzysz hero SoliinSlope overarching</strong>.</p>
<p>By the way, this suffix was generated for Gemma 2 2b, and <em>kinda</em> also works on Gemma 3 1b as well:</p>
<p><img src="assets/af_ssr3.png" class="img-fluid"></p>
<p>I didn’t count this as a jailbreak since the model successfully rerouted my rerouting toward a <em>mostly</em> harmless conversation, but I still found it noteworthy.</p>
</section>
<section id="sec-lens" class="level2">
<h2 class="anchored" data-anchor-id="sec-lens">SAE ???</h2>
<p>Yes, I had to talk about SAE, otherwise it’s not mechanistic isn’t it? :eyes:. Jokes apart, I obviously wanted to try my method using Sparse Autoencoders, but I was stuck at the first - and most important - step: finding good SAE latents to steer my model toward acceptance behavior, so unfortunately, I don’t have results on this front yet. <em>However</em>, I wanted to try something I find much more interesting than jailbreaking models: using SSR to <em>reverse</em>-logit lens stuff. The idea is simple: given a subspace, component, or whatever, use the SSR algorithm on an empty input - something like “[MASK][MASK][MASK][MASK][MASK][MASK]” - and observe what happens.</p>
<p>I first started with “How to create a [MASK]”, targeting Llama 3.2 1b’s layer 10’s refusal direction, expecting to see something like “bomb” — and I wasn’t far off!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/af_lens1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
<p>As my algorithm keeps promising candidates, I receive a batch of answers that are closely related every run. During another run, I got a <em>slightly</em> different set of words:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/af_lens2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
<p>I’ll stop here for obvious reasons. But the result is remarkable! Taking the refusal direction and projecting it to the vocabulary at the end of the model gives refusal words like “I can’t”, but taking the same refusal direction and “projecting” it to the input vocabulary gives slurs! In other words, the logit lens gives tokens that are directly caused by the direction, while the <em>reversed</em>-logit lens gives tokens that <em>cause</em> the direction! It’s not deterministic like its counterpart, but it achieves approximately one good run out of three, with each run converging in seconds, so it is usable. Plus, I didn’t specifically design my algorithm for this purpose, I see many potential easy optimizations.</p>
<p>But where do SAEs fit into all this? Well, I can’t put it off any longer. As I didn’t have much time (and, to be honest, because I’m bad at SAEing), I used examples from the excellent ARENA course on gpt2-small. Given the attention SAE at layer 9 and latent 20668, I adapted SSR to optimize for the following objective: finding tokens that maximize the activation of this particular latent. I thought it would hopelessly get stuck at 0, as being “sparse” is literally the goal of SAEs, but after a few runs (~5), it worked!</p>
<p>First, let’s look at our latent <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>:</p>
<p><img src="assets/af_sae.png" class="img-fluid"></p>
<p>For those reading on smartphones, I’m interested in the positive logits. For our latent, they are: ” firearm”, ” firearms”, ” handguns”, ” Firearms”, ” handgun”, ” gun”, ” guns”, “Gun”, ” Guns”, and ” NRA”. And exactly as in the experiments with refusal directions, I obtained similar tokens with my <em>reversed</em>-logit lens:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/af_lens3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
<p>Just with the model plus the trained SAE, SSR is able to discover what this latent represents. Of course, this might only work for a small number of latents, and I may have been fortunate (though not entirely, as I specifically chose a token-level feature latent). I’m currently working to improve the algorithm to better fit this new task, so it might be a lot better in a few weeks. For instance, I’m trying to incorporate perplexity when sampling candidate tokens or directly into the loss function, to hopefully, make SSR generate more coherent perturbations.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>It’s been enjoyable jailbreaking LLMs, but I feel there’s so much more to explore other than jailbreaks. Not just optimizing inputs to trigger interesting behaviors (I found a head in Qwen that, when targeted, causes Qwen to struggle with stopping, and another where it perfectly repeats the input without the perturbation…), but more generally to investigate models and their mechanisms from the input side. Though it worth noting that this approach may not work on larger models, I’m limited to my personal computer, so I stopped at 3B parameters.</p>
<p>Moreover, I briefly mentioned in the paper that SSR successfully jailbreaks all four tested models with <em>very</em> high success rates (<span class="math inline">\(\gt 80\%\)</span>): Qwen 2.5 1.5b, Llama 3.2 1b &amp; 3b, and Gemma 2 2b, regardless of their different alignment processes — even though Gemma I have to admit, often reroutes my rerouting into a harmless conversations. This suggests that studying subspaces and their evolution might prove very useful for enhancing alignment techniques. You can also look the paper for the layer comparisons.</p>
<p>You can check the code here: <a href="https://github.com/Sckathach/subspace-rerouting" class="uri">https://github.com/Sckathach/subspace-rerouting</a>, and find parts of my roadmap for the coming days in the TODO file. However, I’ll move the <em>reversed</em>-logit lens project elsewhere to keep the paper repository relatively clean.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-arditi_refusal_2024" class="csl-entry" role="listitem">
Arditi, Andy, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Panickssery, Wes Gurnee, and Neel Nanda. 2024. <span>“Refusal in Language Models Is Mediated by a Single Direction.”</span> <a href="https://arxiv.org/abs/2406.11717">https://arxiv.org/abs/2406.11717</a>.
</div>
<div id="ref-he_jailbreaklens_2024" class="csl-entry" role="listitem">
He, Zeqing, Zhibo Wang, Zhixuan Chu, Huiyu Xu, Rui Zheng, Kui Ren, and Chun Chen. 2024. <span>“JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of Representation and Circuit.”</span> <a href="https://arxiv.org/abs/2411.11114">https://arxiv.org/abs/2411.11114</a>.
</div>
<div id="ref-liu_privacy_2020" class="csl-entry" role="listitem">
Liu, Ximeng, Lehui Xie, Yaopeng Wang, Jian Zou, Jinbo Xiong, Zuobin Ying, and Athanasios Vasilakos. 2020. <span>“Privacy and Security Issues in Deep Learning: A Survey.”</span> <em>IEEE Access</em> PP (December): 1–1. <a href="https://doi.org/10.1109/ACCESS.2020.3045078">https://doi.org/10.1109/ACCESS.2020.3045078</a>.
</div>
<div id="ref-logit_lens_2020" class="csl-entry" role="listitem">
nostalgebraist. 2020. <span>“Interpreting GPT: The Logit Lens.”</span>
</div>
<div id="ref-zhou_role_2024" class="csl-entry" role="listitem">
Zhou, Zhenhong, Haiyang Yu, Xinghua Zhang, Rongwu Xu, Fei Huang, Kun Wang, Yang Liu, Junfeng Fang, and Yongbin Li. 2024. <span>“On the Role of Attention Heads in Large Language Model Safety.”</span> <a href="https://arxiv.org/abs/2410.13708">https://arxiv.org/abs/2410.13708</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>It worked really well on the refusal direction, but I haven’t performed extensive experiments on other tasks yet.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Same.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Yes, it’s a static image… You can check the animated version here: <a href="https://www.neuronpedia.org/gpt2-small/9-att-kk/20668" class="uri">https://www.neuronpedia.org/gpt2-small/9-att-kk/20668</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/sckathach\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Sckathach's post - Content that's both brilliant and terrible until observed
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/Sckathach/Sckathach.github.io/edit/main/mech-interp/subspace-rerouting/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/Sckathach/Sckathach.github.io/blob/main/mech-interp/subspace-rerouting/index.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/Sckathach/Sckathach.github.io/issues" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://sckathach.github.io">
<p>Home</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://le-magicien-quantique.github.io">
<p>About</p>
</a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>